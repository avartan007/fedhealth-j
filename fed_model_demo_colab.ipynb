{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FedHealth-J — One-Click Colab Demo\n",
    "This notebook is a self-contained demo of **FedHealth-J**:\n",
    "- clones the repo (if not present),\n",
    "- installs minimal dependencies,\n",
    "- generates the synthetic **J-Health100** dataset,\n",
    "- applies Japanese cultural/seasonal adjustments,\n",
    "- simulates 5 federated clients training an LSTM autoencoder locally,\n",
    "- performs simple federated averaging,\n",
    "- computes anomaly (reconstruction) scores and prints example JSON alerts.\n",
    "\n",
    "**Run each cell in order.** Designed for reviewers/professors — no local setup required."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "!pip install --quiet numpy pandas tensorflow scikit-learn\n",
    "import os, sys, subprocess\n",
    "REPO_URL = \"https://github.com/avartan007/fedhealth-j.git\"\n",
    "REPO_DIR = \"/content/fedhealth-j\"\n",
    "if not os.path.isdir(REPO_DIR):\n",
    "    print(\"Cloning repository...\")\n",
    "    subprocess.run([\"git\", \"clone\", REPO_URL, REPO_DIR])\n",
    "sys.path.insert(0, REPO_DIR)\n",
    "os.listdir(REPO_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from importlib import reload\n",
    "import j_health_100_generator as gen\n",
    "import cultural_profile as cp\n",
    "reload(gen); reload(cp)\n",
    "print(\"Imported local modules\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df = gen.generate_j_health_100()\n",
    "print(\"Generated dataset size:\", len(df))\n",
    "df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "adjusted = []\n",
    "for _, r in df.iterrows():\n",
    "    profile = cp.CulturalProfile(r['region'], r['season'])\n",
    "    hr = profile.adjust_heart_rate(float(r['avg_heart_rate']))\n",
    "    steps = profile.adjust_steps(int(r['daily_steps']))\n",
    "    sleep = float(r['sleep_hours'])\n",
    "    adjusted.append([hr, steps, sleep])\n",
    "X = np.array(adjusted)\n",
    "TIMESTEPS = 10\n",
    "X_seq = np.repeat(X[:, np.newaxis, :], TIMESTEPS, axis=1)\n",
    "print(\"Prepared sequence data shape:\", X_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, RepeatVector, TimeDistributed, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "def create_lstm_autoencoder(timesteps=TIMESTEPS, features=3, latent_dim=16):\n",
    "    model = Sequential([\n",
    "        LSTM(32, activation='relu', input_shape=(timesteps, features), return_sequences=True),\n",
    "        LSTM(latent_dim, activation='relu', return_sequences=False),\n",
    "        RepeatVector(timesteps),\n",
    "        LSTM(latent_dim, activation='relu', return_sequences=True),\n",
    "        LSTM(32, activation='relu', return_sequences=True),\n",
    "        TimeDistributed(Dense(features))\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(1e-3), loss='mse')\n",
    "    return model\n",
    "m = create_lstm_autoencoder()\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "NUM_CLIENTS = 5\n",
    "client_splits = np.array_split(X_seq, NUM_CLIENTS)\n",
    "client_models = []\n",
    "client_weights = []\n",
    "client_sizes = []\n",
    "for idx, data in enumerate(client_splits):\n",
    "    model = create_lstm_autoencoder()\n",
    "    model.fit(data, data, epochs=1, batch_size=8, verbose=0)\n",
    "    client_models.append(model)\n",
    "    client_weights.append(model.get_weights())\n",
    "    client_sizes.append(len(data))\n",
    "    print(f\"Client {idx+1} trained on {len(data)} samples.\")\n",
    "def weighted_average(weights_list, sizes):\n",
    "    avg = []\n",
    "    total = float(sum(sizes))\n",
    "    for layer_weights in zip(*weights_list):\n",
    "        layer_sum = np.zeros_like(layer_weights[0])\n",
    "        for w, s in zip(layer_weights, sizes):\n",
    "            layer_sum += w * (s/total)\n",
    "        avg.append(layer_sum)\n",
    "    return avg\n",
    "global_weights = weighted_average(client_weights, client_sizes)\n",
    "global_model = create_lstm_autoencoder()\n",
    "global_model.set_weights(global_weights)\n",
    "print(\"Federated averaging complete. Global model ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "recon = global_model.predict(X_seq, verbose=0)\n",
    "mse_per_sample = np.mean(np.square(recon - X_seq), axis=(1,2))\n",
    "threshold = mse_per_sample.mean() + 1.5 * mse_per_sample.std()\n",
    "anomaly_indices = np.where(mse_per_sample > threshold)[0]\n",
    "alerts = []\n",
    "for idx in anomaly_indices[:5]:\n",
    "    uid = df.loc[idx, 'user_id']\n",
    "    reason = []\n",
    "    if df.loc[idx, 'avg_heart_rate'] > df['avg_heart_rate'].mean() + 5:\n",
    "        reason.append(\"Elevated heart rate vs baseline\")\n",
    "    if df.loc[idx, 'daily_steps'] < df['daily_steps'].mean() - 1000:\n",
    "        reason.append(\"Low activity (steps)\")\n",
    "    if df.loc[idx, 'sleep_hours'] < 5.5:\n",
    "        reason.append(\"Short sleep duration\")\n",
    "    alert = {\n",
    "        \"timestamp\": datetime.utcnow().isoformat() + \"Z\",\n",
    "        \"user_id\": uid,\n",
    "        \"anomaly_score\": float(mse_per_sample[idx]),\n",
    "        \"reason\": \"; \".join(reason) if reason else \"Unusual multivariate pattern\",\n",
    "        \"recommendation\": \"Please check vitals and recent environment (heat/cold/fall risk)\"\n",
    "    }\n",
    "    alerts.append(alert)\n",
    "print(\"Anomaly threshold (demo):\", float(threshold))\n",
    "print(\"Number of anomalies detected (demo):\", int(len(anomaly_indices)))\n",
    "print(json.dumps(alerts, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "OUT_PATH = \"/content/fedhealth-j/sample_anomalies.json\"\n",
    "with open(OUT_PATH, \"w\") as f:\n",
    "    json.dump(alerts, f, indent=2)\n",
    "print(\"Saved sample anomaly file to:\", OUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done — what you just ran\n",
    "- Synthetic dataset generated: `j_health_100.csv`\n",
    "- Data adjusted using cultural profiles\n",
    "- Local federated training simulated (5 clients)\n",
    "- Global model produced via simple federated averaging\n",
    "- Anomaly scores computed and sample JSON alerts saved to `sample_anomalies.json`\n",
    "\n",
    "Professors can click **Run All** directly in Colab. This notebook is self-contained."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 10
}
